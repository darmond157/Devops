# -- Cloud service being deployed on (example: `aws`, `azure`, `do`, `gcp`, `other`).
cloud: other

# -- Notification email for notifications to be sent to from the PostHog stack
notificationEmail: temp@temp.temp

# -- Site url specifies the canonical URL root the site can be accessed using.
# This is used to e.g. generate shareable links to Dashboards.
siteUrl: https://k8s-posthog.bardia-rk.ir

image:
  repository: posthog/posthog
  sha:
  tag: dcaf95f40bba8d880496abf730394379076816c4
  default: ":latest"
  pullPolicy: Always
  pullSecrets: []

# -- Sentry endpoint to send errors to.
sentryDSN:

# -- Django SECRET_KEY to use for hashing e.g. passwords. See
# https://docs.djangoproject.com/en/4.0/ref/settings/#secret-key
posthogSecretKey:
  # -- Specify that the key should be pulled from an existing secret key. By
  # default the chart will generate a secret and create a Kubernetes Secret
  # containing it.
  existingSecret:
  # -- Specify the key within the secret from which SECRET_KEY should be taken.
  existingSecretKey: posthog-secret

migrate:
  # -- Whether to install the PostHog migrate job or not.
  enabled: true

events:
  # -- Whether to install the PostHog events stack or not.
  enabled: true
  # -- Count of events pods to run. This setting is ignored if `events.hpa.enabled` is set to `true`.
  replicacount: 1

web:
  enabled: true
  image: {}
  replicacount: 1

worker:
  enabled: true
  replicacount: 1
  consumers:
    - name: default

plugins:
  enabled: true
  replicacount: 1
  env: []
  resources: {}
  # -- Sentry endpoint to send errors to. Falls back to global sentryDSN
  sentryDSN:

email:
  # -- SMTP service host.
  host:
  # -- SMTP service port.
  port:
  # -- SMTP service user.
  user:
  # -- SMTP service password.
  password:
  # -- Name of an existing Kubernetes secret object containing the SMTP service password.
  existingSecret: ""
  # -- Name of the key pointing to the password in your Kubernetes secret.
  existingSecretKey: ""
  # -- Use TLS to authenticate to the SMTP service.
  use_tls: true
  # -- Use SSL to authenticate to the SMTP service.
  use_ssl:
  # -- Outbound email sender to use.
  from_email:

service:
  name: posthog
  type: NodePort
  externalPort: 8000
  internalPort: 8000

ingress:
  enabled: true
  hostname:
  # -- Extra annotations
  annotations: {}
  # -- TLS secret to be used by the ingress.
  secretName:

postgresql:
  enabled: false

externalPostgresql:
  postgresqlHost: posthog-test-database.sandbox-bardia-rk.svc
  postgresqlPort: 5432
  postgresqlDatabase: postgres
  postgresqlUsername: postgres
  postgresqlPassword: n5O2TvDvpEdXulnJrMsj

redis:
  enabled: false

externalRedis:
  host: "posthog-test-redis.sandbox-bardia-rk.svc"
  port: 6379
  password: "wY1nwuEGyNE72LdCQMkNVfHuZo37Vyr2"

# externalSessionRecordingRedis:
#   host: ""
#   port: 6379

kafka:
  # -- Whether to deploy Kafka as part of this release. To use an external Kafka instance set this to `false` and configure the `externalKafka` values.
  enabled: true

  image:
    repository: "bitnamilegacy/kafka"
    tag: "2.8.1-debian-11-r7"

  nameOverride: posthog-kafka

  fullnameOverride: ""

  # -- A size-based retention policy for logs.
  logRetentionBytes: _15_000_000_000

  # -- The minimum age of a log file to be eligible for deletion due to age.
  logRetentionHours: 24

  # -- The default number of log partitions per topic.
  numPartitions: 1

  persistence:
    # - Enable data persistence using PVC.
    enabled: false
    # -- PVC Storage Request for Kafka data volume.
    size: 20Gi

  zookeeper:
    # -- Switch to enable or disable the ZooKeeper helm chart. !!! Please DO NOT override this (this chart installs Zookeeper separately) !!!
    enabled: false

  externalZookeeper:
    # -- List of external zookeeper servers to use.
    servers:
      - posthog-posthog-zookeeper:2181

externalKafka:
  # - External Kafka brokers. Ignored if `kafka.enabled` is set to `true`. Multiple brokers can be provided as array/list.
  brokers: []
  # - Use TLS to connect to the external kafka cluster
  tls: false

externalSessionRecordingKafka:
  # - External Kafka brokers for session recordings. Ignored if `kafka.enabled` is set to `true`. Multiple brokers can be provided as array/list.
  brokers: []
  # - Use TLS to connect to the external kafka cluster
  tls: false

###
###
### ---- TEMPORAL SCHEDULER ----
### TODO: add support for a self-hosted scheduler in another PR.
###
externalTemporal:
  # - External Temporal scheduler's hostname
  host: ""
  # - External Temporal scheduler's port
  port: 7233
  # - Namespace to register into
  namespace: ""

###
###
### ---- ZOOKEEPER ----
###
###
zookeeper:
  enabled: true
  nameOverride: posthog-zookeeper
  replicaCount: 1
  autopurge:
    # -- The time interval (in hours) for which the purge task has to be triggered
    purgeInterval: 1
  persistence:
    enabled: false
  image:
    registry: ghcr.io/element-hq
    repository: bitnamilegacy/zookeeper
    tag: 3.7.0-debian-10-r70

clickhouse:
  # -- Whether to install clickhouse. If false, `clickhouse.host` must be set
  enabled: true
  # -- Which namespace to install clickhouse and the `clickhouse-operator` to (defaults to namespace chart is installed to)
  namespace:
  # -- Clickhouse cluster
  cluster: posthog
  # -- Clickhouse database
  database: posthog
  # -- Clickhouse user
  user: admin
  # -- Clickhouse password
  password: a1f31e03-c88e-4ca6-a2df-ad49183d15d9
  # -- Clickhouse existing secret name that needs to be in the namespace where
  # posthog is deployed into. Will not use the above password value if set
  existingSecret: ""
  # -- Key in the existingSecret containing the password value
  existingSecretPasswordKey: ""
  # -- Whether to use TLS connection connecting to ClickHouse
  secure: false
  # -- Whether to verify TLS certificate on connection to ClickHouse
  verify: false
  # -- List of external Zookeeper servers to use.
  # externalZookeeper:
  #   servers:
  #     - host: host1
  #       port: 2181
  #     - host: host2
  #       port: 2181
  #     - host: host3
  #       port: 2181

  image:
    # -- ClickHouse image repository.
    repository: clickhouse/clickhouse-server
    # -- ClickHouse image tag. Note: PostHog does not support all versions of ClickHouse. Please override the default only if you know what you are doing.
    tag: "23.9.2"
    # -- Image pull policy
    pullPolicy: IfNotPresent
    ## Optionally specify an array of imagePullSecrets.
    ## Secrets must be manually created in the namespace.
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ## Example:
    ## pullSecrets:
    ##   - myRegistryKeySecretName
    ##
    pullSecrets: []

  # -- Toleration labels for clickhouse pod assignment
  tolerations: []
  # -- Affinity settings for clickhouse pod
  affinity: {}
  # -- Clickhouse resource requests/limits. See more at http://kubernetes.io/docs/user-guide/compute-resources/
  resources: {}
  #   limits:
  #     cpu: 1000m
  #     memory: 16Gi
  #   requests:
  #     cpu: 4000m
  #     memory: 16Gi
  securityContext:
    enabled: true
    runAsUser: 101
    runAsGroup: 101
    fsGroup: 101

  # -- Kubernetes Service type.
  serviceType: ClusterIP

  # -- An allowlist of IP addresses or network masks the ClickHouse user is
  # allowed to access from. By default anything within a private network will be
  # allowed. This should suffice for most use case although to expose to other
  # networks you will need to update this setting.
  #
  # For more details on usage, see https://posthog.com/docs/self-host/deploy/configuration#securing-clickhouse
  allowedNetworkIps:
    - "10.0.0.0/8"
    - "172.16.0.0/12"
    - "192.168.0.0/16"

  persistence:
    # -- Enable data persistence using PVC.
    enabled: false

    # -- Use a manually managed Persistent Volume and Claim.
    #    If defined, PVC must be created manually before volume will be bound.
    #
    existingClaim: ""

    # -- Persistent Volume Storage Class to use.
    #    If defined, `storageClassName: <storageClass>`.
    #    If set to `storageClassName: ""`, disables dynamic provisioning.
    #    If undefined (the default) or set to `null`, no storageClassName spec is
    #    set, choosing the default provisioner.
    #
    storageClass: null

    # -- Persistent Volume size
    size: 20Gi

  ## -- Clickhouse user profile configuration.
  ## You can use this to override profile settings, for example `default/max_memory_usage: 40000000000`
  ## For the full list of settings, see:
  ## - https://clickhouse.com/docs/en/operations/settings/settings-profiles/
  ## - https://clickhouse.com/docs/en/operations/settings/settings/
  profiles: {}

  ## -- Default user profile configuration for Clickhouse. !!! Please DO NOT override this !!!
  defaultProfiles:
    default/allow_experimental_window_functions: "1"
    default/allow_nondeterministic_mutations: "1"

  ## -- Clickhouse cluster layout. (Experimental, use at own risk)
  ## For a full list of options, see https://github.com/Altinity/clickhouse-operator/blob/master/docs/custom_resource_explained.md
  ## section on clusters and layouts.
  layout:
    shardsCount: 1
    replicasCount: 1

  ## -- ClickHouse settings configuration.
  ## You can use this to override settings, for example `prometheus/port: 9363`
  ## For the full list of settings, see:
  ## - https://clickhouse.com/docs/en/operations/settings/settings/
  settings:
    {}
    # Uncomment those lines if you want to enable the built-in Prometheus HTTP endpoint in ClickHouse.
    # prometheus/endpoint: /metrics
    # prometheus/port: 9363
    # prometheus/metrics: true
    # prometheus/events: true
    # prometheus/asynchronous_metrics: true

  ## -- Default settings configuration for ClickHouse. !!! Please DO NOT override this !!!
  defaultSettings:
    default_database: "posthog"
    format_schema_path: /etc/clickhouse-server/config.d/

  ## -- specify additional user configs for ClickHouse. This will be added to
  ## the users.xml configuration. See
  ## https://github.com/Altinity/clickhouse-operator for details.
  additionalUsersConfig:

  client:
    image:
      repository: clickhouse/clickhouse-server
      tag: "23.9.2.56"


## External clickhouse configuration
##
externalClickhouse:
  # -- Host of the external cluster. This is required when clickhouse.enabled is false
  host:
  # -- Name of the external cluster to run DDL queries on. This is required when clickhouse.enabled is false
  cluster:
  # -- Database name for the external cluster
  database: posthog
  # -- User name for the external cluster to connect to the external cluster as
  user:
  # -- Password for the cluster. Ignored if existingClickhouse.existingSecret is set
  password:
  # -- Name of an existing Kubernetes secret object containing the password
  existingSecret:
  # -- Name of the key pointing to the password in your Kubernetes secret
  existingSecretPasswordKey:
  # -- Whether to use TLS connection connecting to ClickHouse
  secure: false
  # -- Whether to verify TLS connection connecting to ClickHouse
  verify: false

###
###
### ---- MINIO (Object Storage system) ----
###
###
minio:
  # -- Whether to install MinIO (object storage system) or not. You can keep it disabled or rely on `externalObjectStorage` if you want to use a managed object storage service (AWS S3, Google Cloud Storage, ...).
  enabled: false
  auth:
    # -- MinIO root username
    rootUser: root-user
    # -- MinIO root password
    rootPassword: root-password-change-me-please
    # -- Use existing secret for credentials details (`auth.rootUser` and `auth.rootPassword` will be ignored and picked up from this secret). The secret has to contain the keys `root-user` and `root-password`)
    existingSecret:
  persistence:
    # -- Enable MinIO data persistence using PVC.
    enabled: false
  # -- Comma, semi-colon or space separated list of buckets to create at initialization (only in standalone mode)
  defaultBuckets: "posthog"
  # -- Disable MinIO Web UI
  disableWebUI: true

  # We are overriding the default service ports as they collide with ClickHouse
  service:
    ports:
      # -- MinIO API service port
      api: "19000"
      # -- MinIO Console service port
      console: "19001"

  ## -- MinIO pod(s) annotation.
  podAnnotations:
    # Uncomment those lines if you want Prometheus server to scrape MinIO pods metrics.
    # prometheus.io/scrape: "true"
    # prometheus.io/path: "/minio/v2/metrics/cluster"
    # prometheus.io/port: "9000"

## External Object Storage configuration
##
externalObjectStorage:
  # -- Endpoint of the external object storage. e.g. https://s3.us-east-1.amazonaws.com
  endpoint:
  # -- Host of the external object storage. Deprecated: use endpoint instead
  host:
  # -- Port of the external object storage. Deprecated: use endpoint instead
  port:
  # -- Bucket name to use.
  bucket:
  # -- Region of the bucket (for AWS).
  region:
  # -- Name of an existing Kubernetes secret object containing the `access_key_id` and `secret_access_key`. The secret has to contain the keys `root-user` and `root-password`).
  existingSecret:

###
###
### ---- MISC ----
###
###
installCustomStorageClass: false

busybox:
  # -- Specify the image to use for e.g. init containers
  image: busybox:1.34
  # -- Image pull policy
  pullPolicy: IfNotPresent
  ## Optionally specify an array of imagePullSecrets.
  ## Secrets must be manually created in the namespace.
  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  ## Example:
  ## pullSecrets:
  ##   - myRegistryKeySecretName
  ##
  pullSecrets: []

# -- Kubernetes cluster domain name
clusterDomain: cluster.local

# Whether to set a topologySpreadConstraint on all deployments
# to balance pods between availability zones and nodes
includeDefaultTopologySpreadConstraints: false

_pgbouncer: &_pgbouncer 
# -- Whether to deploy a PgBouncer service to satisfy the applications requirements.
  enabled: false
